{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8YtBH9l2cc_",
        "outputId": "b2882814-8728-4ccf-9d7b-0162fce5e5c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lendo: SAEB_UNIFICADO_2019.csv ...\n",
            "Lendo: SAEB_UNIFICADO_2017.csv ...\n",
            "Lendo: SAEB_UNIFICADO_2021.csv ...\n",
            "Lendo: SAEB_UNIFICADO_2023.csv ...\n",
            "\n",
            "Unificação concluída.\n",
            "Arquivo salvo em: SAEB_MT_UNIFICADO.csv\n",
            "Arquivos processados: 4\n",
            "Linhas totais no unificado: 7585929\n",
            "\n",
            "Contagem por classificação1:\n",
            "classificação1\n",
            "Básico          4048241\n",
            "Insuficiente    2247109\n",
            "Proficiente     1123206\n",
            "Avançado         167373\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Contagem por classificação2:\n",
            "classificação2\n",
            "Insuficiente    6295350\n",
            "Proficiente     1290579\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# unifica_saeb.py\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "import unicodedata\n",
        "import re\n",
        "import sys\n",
        "\n",
        "# -------- CONFIGURAÇÃO (ajuste se quiser) --------\n",
        "FILE_PATTERN = \"SAEB_UNIFICADO_*.csv\"  # padrão para localizar seus arquivos\n",
        "SEP = ';'                              # separador informado por você\n",
        "ENC = 'latin-1'                        # encoding informado por você\n",
        "PROF_COL_STANDARD = \"PROFICIENCIA_MT_SAEB\"  # nome que vamos usar internamente\n",
        "OUTFILE = \"SAEB_MT_UNIFICADO.csv\"   # arquivo de saída\n",
        "# -------------------------------------------------\n",
        "\n",
        "def normalize(name):\n",
        "    \"\"\"Normaliza um nome de coluna: remove acentos, pontuação e espaços, retorna minúsculo.\"\"\"\n",
        "    if not isinstance(name, str):\n",
        "        return \"\"\n",
        "    s = name.strip().lower()\n",
        "    s = unicodedata.normalize(\"NFKD\", s)\n",
        "    s = \"\".join(ch for ch in s if not unicodedata.combining(ch))\n",
        "    s = re.sub(r'[^a-z0-9]+', '_', s)\n",
        "    s = s.strip('_')\n",
        "    return s\n",
        "\n",
        "def find_prof_col(cols):\n",
        "    \"\"\"\n",
        "    Tenta identificar a coluna de proficiência entre uma lista de colunas.\n",
        "    Estratégia:\n",
        "      1) match exato sobre o nome normalizado do padrão\n",
        "      2) checar presença simultânea dos tokens 'proficiencia','mt','saeb'\n",
        "      3) fallback: qualquer coluna que contenha 'proficiencia'\n",
        "    Retorna o nome original da coluna se encontrada, ou None.\n",
        "    \"\"\"\n",
        "    normalized_target = normalize(PROF_COL_STANDARD)\n",
        "    # 1) match exato\n",
        "    for c in cols:\n",
        "        if normalize(c) == normalized_target:\n",
        "            return c\n",
        "    # 2) tokens principais\n",
        "    tokens = ['proficiencia', 'mt', 'saeb']\n",
        "    for c in cols:\n",
        "        nc = normalize(c)\n",
        "        if all(tok in nc for tok in tokens):\n",
        "            return c\n",
        "    # 3) fallback por 'proficiencia'\n",
        "    for c in cols:\n",
        "        if 'proficiencia' in normalize(c):\n",
        "            return c\n",
        "    return None\n",
        "\n",
        "def read_csv_safe(path):\n",
        "    \"\"\"Lê CSV com SEP e ENC definidos; retorna DataFrame ou lança erro detalhado.\"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(path, sep=SEP, encoding=ENC)\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(f\"Erro lendo '{path}' com sep='{SEP}' e encoding='{ENC}': {e}\")\n",
        "\n",
        "def classificacao1(score):\n",
        "    \"\"\"Intervalos contínuos para valores decimais.\"\"\"\n",
        "    if pd.isna(score):\n",
        "        return pd.NA\n",
        "    s = float(score)\n",
        "    if s < 225:\n",
        "        return 'Insuficiente'\n",
        "    elif 225 <= s < 300:\n",
        "        return 'Básico'\n",
        "    elif 300 <= s < 350:\n",
        "        return 'Proficiente'\n",
        "    elif s >= 350:\n",
        "        return 'Avançado'\n",
        "    return pd.NA\n",
        "\n",
        "def classificacao2(c1):\n",
        "    \"\"\"Agrupa Básico+Insuficiente => Insuficiente; Proficiente+Avançado => Proficiente\"\"\"\n",
        "    if pd.isna(c1):\n",
        "        return pd.NA\n",
        "    if c1 in ['Insuficiente', 'Básico']:\n",
        "        return 'Insuficiente'\n",
        "    if c1 in ['Proficiente', 'Avançado']:\n",
        "        return 'Proficiente'\n",
        "    return pd.NA\n",
        "\n",
        "def main():\n",
        "    files = glob(FILE_PATTERN)\n",
        "    if not files:\n",
        "        print(f\"Nenhum arquivo encontrado com padrão '{FILE_PATTERN}'. Ajuste FILE_PATTERN ou coloque os CSVs na mesma pasta.\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    dfs = []\n",
        "    arquivos_sem_prof = []\n",
        "    for f in files:\n",
        "        print(f\"Lendo: {f} ...\")\n",
        "        df = read_csv_safe(f)\n",
        "        # limpa espaços nas colunas (mantém o nome original)\n",
        "        df.columns = [c.strip() if isinstance(c, str) else c for c in df.columns]\n",
        "        prof_col = find_prof_col(df.columns)\n",
        "        if prof_col is None:\n",
        "            arquivos_sem_prof.append(f)\n",
        "            dfs.append(df)  # inclui mesmo assim; terá NaNs na coluna padrão\n",
        "        else:\n",
        "            # renomeia a coluna detectada para o nome padrão uniforme\n",
        "            if prof_col != PROF_COL_STANDARD:\n",
        "                df = df.rename(columns={prof_col: PROF_COL_STANDARD})\n",
        "            dfs.append(df)\n",
        "\n",
        "    if arquivos_sem_prof:\n",
        "        msg = (\"Atenção: os seguintes arquivos NÃO tiveram a coluna de proficiência detectada \"\n",
        "               f\"(baseada em '{PROF_COL_STANDARD}'):\\n\" + \"\\n\".join(arquivos_sem_prof) +\n",
        "               \"\\n\\nEles foram incluídos, mas a coluna de proficiência ficará com NaN nesses casos. \"\n",
        "               \"Se isso for inesperado, verifique os cabeçalhos desses arquivos.\")\n",
        "        print(msg)\n",
        "\n",
        "    # união das colunas (ordem por primeira aparição)\n",
        "    all_cols = []\n",
        "    for df in dfs:\n",
        "        for c in df.columns:\n",
        "            if c not in all_cols:\n",
        "                all_cols.append(c)\n",
        "\n",
        "    # Se a coluna padrão não apareceu em nenhum arquivo, informar e abortar\n",
        "    if PROF_COL_STANDARD not in all_cols:\n",
        "        print(f\"ERRO: Nenhuma coluna detectada foi renomeada para '{PROF_COL_STANDARD}'. \"\n",
        "              \"Verifique os cabeçalhos dos arquivos ou ajuste a função de detecção.\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    # reindexa (preenche NaN onde coluna ausente) e concatena\n",
        "    dfs = [df.reindex(columns=all_cols) for df in dfs]\n",
        "    df_all = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "    # converte proficiência para numérico\n",
        "    df_all[PROF_COL_STANDARD] = pd.to_numeric(df_all.get(PROF_COL_STANDARD), errors='coerce')\n",
        "\n",
        "    # aplica classificações\n",
        "    df_all['classificação1'] = df_all[PROF_COL_STANDARD].apply(classificacao1)\n",
        "    df_all['classificação2'] = df_all['classificação1'].apply(classificacao2)\n",
        "\n",
        "    # salva em utf-8-sig (bom para Excel)\n",
        "    df_all.to_csv(OUTFILE, index=False, encoding='utf-8-sig')\n",
        "\n",
        "    # resumo\n",
        "    print(\"\\nUnificação concluída.\")\n",
        "    print(\"Arquivo salvo em:\", OUTFILE)\n",
        "    print(\"Arquivos processados:\", len(files))\n",
        "    print(\"Linhas totais no unificado:\", len(df_all))\n",
        "    print(\"\\nContagem por classificação1:\")\n",
        "    print(df_all['classificação1'].value_counts(dropna=False))\n",
        "    print(\"\\nContagem por classificação2:\")\n",
        "    print(df_all['classificação2'].value_counts(dropna=False))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ]
}